
@CONFERENCE{Ji2019957,
author={Ji, M.},
title={UIChecker: An Automatic Detection Platform for Android GUI Errors},
journal={Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
year={2019},
volume={2018-November},
pages={957-961},
doi={10.1109/ICSESS.2018.8663923},
art_number={8663923},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063610547&doi=10.1109%2fICSESS.2018.8663923&partnerID=40&md5=bc0dadd77d7c415feb4fa07501254be2},
affiliation={School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University Shanghai, Shanghai, 200240, China},
abstract={At present, Android automated GUI testing has been widely used in mobile application testing. Automated GUI test input generation technology and tools are hot topics for practitioners, but errors in some test screenshots generated by automated test input tools still need to be reviewed manually. In this paper, we creatively proposed an automatic detection platform for GUI errors, detecting the GUI errors of mobile related and image-related widget error classification model through machine learning, which detects the error of widgets. On all experimental App test sets, the accuracy of the text-related widget error classification model reached an average of 98.06%, and the accuracy of image-related widgets error classification model achieved an average of 95.44%, which greatly reduced the time cost of reviewing GUI errors manually. In addition, we analyze the relative positional relationship between the widgets, and use the Wilson score sorting algorithm to analyze the symbiosis and interdependence between the widgets, and finally generate the assertion tables, thus more complex GUI errors can be detected. © 2018 IEEE.},
author_keywords={assertions;  automated GUI testing;  automated traversal tool;  GUI error detection;  machine learning},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Coppola201967,
author={Coppola, R. and Morisio, M. and Torchiano, M.},
title={Mobile GUI Testing Fragility: A Study on Open-Source Android Applications},
journal={IEEE Transactions on Reliability},
year={2019},
volume={68},
number={1},
pages={67-90},
doi={10.1109/TR.2018.2869227},
art_number={8477182},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054372646&doi=10.1109%2fTR.2018.2869227&partnerID=40&md5=98595f962167bf470715b130aa43c52c},
affiliation={Department of Computer Engineering and Automatics, Politecnico di Torino, Torino, 10129, Italy},
abstract={Android applications do not seem to be tested as thoroughly as desktop ones. In particular, graphical user interface (GUI) testing appears generally limited. Like web-based applications, mobile apps suffer from GUI test fragility, i.e., GUI test classes failing or needing updates due to even minor modifications in the GUI or in the application under test. The objective of our study is to estimate the adoption of GUI testing frameworks among Android open-source applications, the quantity of modifications needed to keep test classes up to date, and their amount due to GUI test fragility. We introduce a set of 21 metrics to measure the adoption of testing tools and the evolution of test classes and test methods, and to estimate the fragility of test suites. We computed our metrics for six GUI testing frameworks, none of which achieved a significant adoption among Android projects hosted on GitHub. When present, GUI test methods associated with the considered tools are modified often, and a relevant portion (70% on average) of those modifications is induced by GUI-related fragilities. On average, for the projects considered, more than 7% of the total modified lines of code between consecutive releases belong to test classes developed with the analyzed testing frameworks. The measured percentage was higher on average than the one required by other generic test code, based on the JUnit testing framework. Fragility of GUI tests constitutes a relevant concern, probably an obstacle for developers to adopt test automation. This first evaluation of the fragility of Android scripted GUI testing can constitute a benchmark for developers and testers leveraging the analyzed test tools and the basis for the definition of a taxonomy of fragility causes and guidelines to mitigate the issue. © 2018 IEEE.},
author_keywords={Mobile computing;  software engineering;  software maintenance;  software metrics;  software testing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chu201914,
author={Chu, E.T.-H. and Lin, J.-Y.},
title={Automated GUI testing for android news applications},
journal={Proceedings - 2018 International Symposium on Computer, Consumer and Control, IS3C 2018},
year={2019},
pages={14-17},
doi={10.1109/IS3C.2018.00013},
art_number={8645008},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063236292&doi=10.1109%2fIS3C.2018.00013&partnerID=40&md5=5e8be7185ae4d6f7514723796c568ddf},
affiliation={Department of Electronic and Computer Science Information Engineering, National Yunlin University of Science and Technology, Douliou, Taiwan},
abstract={Automated GUI (graphical user interface) testing tools have been used to help engineers test whether the software GUI is displayed correctly in different smartphones. However, due to different screen aspect ratios, the ratio of width to height, the same content of a mobile application (app) may have a different layout in different smartphones. As a result, the test oracle generated by traditional methods may not be reused for different smartphones and thus prolong the testing process. In this paper, we present a GUI testing tool, named FLAG (Fully Automatic mobile GUI testing), which aims to make the test oracle reusable without compromising test accuracy. In addition, the whole testing process, including generating test cases, simulating user gestures and verifying results, is automatically performed by FLAG without human interaction. News applications have been selected for our study not only because they are popular, but also because they support most commonly-used user gestures, such as tap, scroll, spread and pinch. In our experiment, we selected five commercial Android phones and one popular news apps to evaluate the effectiveness of the FLAG. Our experiment results show that the FLAG performs better than existing methods and can achieve an average accuracy of 95.20% in determining whether a test has passed or failed. © 2018 IEEE.},
author_keywords={Android phone;  GUI testing tools;  Test case generator;  Test oracle},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Eladawy2019327,
author={Eladawy, H.M. and Mohamed, A.E. and Salem, S.A.},
title={A New Algorithm for Repairing Web-Locators using Optimization Techniques},
journal={Proceedings - 2018 13th International Conference on Computer Engineering and Systems, ICCES 2018},
year={2019},
pages={327-331},
doi={10.1109/ICCES.2018.8639336},
art_number={8639336},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063123702&doi=10.1109%2fICCES.2018.8639336&partnerID=40&md5=80ecfc8a881e30db96f590612dee26f8},
affiliation={Department of Electronics, Communication and Computers, Helwan University, Faculty of Engineering, Cairo, Egypt},
abstract={The importance of test automation in the software industry has received a growing attention in recent years and it is continuously increasing. Unfortunately, the maintenance of the test cases is a major problem that faces those who use test automation. This problem becomes bigger when dealing with Graphical User Interface (GUI) tests.In this paper, an algorithm is introduced to maintain GUI tests for web applications. The Genetic algorithm is adopted to automatically repair the locators used to select elements from web pages. The algorithm is evaluated using several applications and results show that the proposed algorithm improves the repair percentage to 87% of the used locators compared to the previous result which was 73%. © 2018 IEEE.},
author_keywords={DOM selectors;  genetic algorithm;  GUI testing;  web testing;  XPath;  XPath locator},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu20194885,
author={Liu, C.-H.},
title={A compatibility testing platform for android multimedia applications},
journal={Multimedia Tools and Applications},
year={2019},
volume={78},
number={4},
pages={4885-4904},
doi={10.1007/s11042-018-6268-y},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049556617&doi=10.1007%2fs11042-018-6268-y&partnerID=40&md5=fc7a70925c66f2730bb0ac2c6b69d7a7},
affiliation={Department of Computer Science and Information Engineering, National Taipei University of Technology, 1, Sec. 3, Chung-Hsiao E. Rd, Taipei, 106, Taiwan},
abstract={Along with the widespread use of smartphones, Android has become one of the major platforms for multimedia applications (apps). However, due to the fast evolution of Android operating system and the fragmentation of Android devices, it becomes important for an Android multimedia app to be tested on different devices to ensure that the app is compatible with and run well on any of the devices so as to provide consistent user experiences. This paper presents a cloud testing platform (CTP) that allows Android multimedia apps to be tested automatically against a scalable number of physical devices in parallel. Particularly, CTP provides five types of testing to ensure the compatibility of apps from different perspectives, including GUI testing, acceptance testing, stress testing, crash testing, and installation/uninstallation testing. Further, to facilitate identifying the bugs of apps, in addition to test results, CTP also provides the video, screenshots, and performance data corresponding to the tests. Moreover, CTP can also generate a GUI state diagram that can be used to analyze app’s behavior and is helpful for crash diagnosis and debugging. The case study shows that CTP can be effective in ensuring the compatibility of Android multimedia apps while saving test time and effort. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Android compatibility testing;  Android testing;  Multimedia app testing;  Software testing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{UsSaqib2019170,
author={Us Saqib, N. and Shahzad, S.},
title={Functionality, performance, and compatibility testing: A model based approach},
journal={Proceedings - 2018 International Conference on Frontiers of Information Technology, FIT 2018},
year={2019},
pages={170-175},
doi={10.1109/FIT.2018.00037},
art_number={8616986},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062396248&doi=10.1109%2fFIT.2018.00037&partnerID=40&md5=b2f5c7586215987023d5843bf09caaef},
affiliation={Department of Computer Science, University of Peshawar, Peshawar, Pakistan},
abstract={Mobile applications have proliferated internet market due to an profuse development and use of smart phones and other mobile devices. Testing of these mobile applications is crucial before these are made available to the customers. Testing mobile applications continues to be a challenge for software developers due to varied hardware features of mobile phones and due to constraints such as small size and portability. Accordingly, testing of the GUI of application for efficiency, reliability and user friendliness has become critical. This paper details an analysis of existing GUI testing techniques to uncover issues in GUI modeling, test automation, cross platform concerns, and automatic test generation and execution. A solution is then proposed named as TriTest which is a model based approach to perform automatic functionality, compatibility, and performance testing of mobile applications. © 2018 IEEE.},
author_keywords={Application under Test (AuT);  Model Based Testing (MBT).;  Software testing;  Test case generation and execution},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Inoue20191,
author={Inoue, U.},
title={GUI testing for introductory object-oriented programming exercises},
journal={Studies in Computational Intelligence},
year={2019},
volume={787},
pages={1-13},
doi={10.1007/978-3-319-96806-3_1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051804410&doi=10.1007%2f978-3-319-96806-3_1&partnerID=40&md5=65c96e3b8a44a7a2533f121d681833f9},
affiliation={Department of Communication and Information Engineering, Tokyo Denki University, Tokyo, Japan},
abstract={Automated testing is necessary in large classrooms where many students learn a programming language. This paper presents a method to test and score student programs with graphical user interfaces written in JavaFX. The method is based on scripts that analyzes the structure of programs under test and simulates user’s interactions. We implemented several utility methods to write the testing scripts easy. No additional software library is required to run the scripts. Preliminary evaluation results are shown on the developing and executing of scripts for real exercises in our introductory programming classrooms. © Springer International Publishing AG, part of Springer Nature 2019.},
author_keywords={Automated scoring;  GUI testing;  Java application;  JavaFX;  Programming education},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ha2019103,
author={Ha, L. and Kang, S. and Lee, J. and Han, Y.},
title={Automatic generation of GUI test inputs using user configurations},
journal={Studies in Computational Intelligence},
year={2019},
volume={786},
pages={103-116},
doi={10.1007/978-3-319-96803-2_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051757675&doi=10.1007%2f978-3-319-96803-2_9&partnerID=40&md5=1fc942e16255cb597535862b6e4418ac},
affiliation={Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Chonbuk National University, Jeonju, South Korea},
abstract={GUI testing validates the functionality of a software-intensive system by exercising its GUI. Although much research on automatic generation of GUI test inputs has been conducted to reduce the cost of GUI testing, the current GUI test input generation techniques can miss testing the behavior of the system which is dependent on the user configuration, which may leave undetected the defects that appear only under a certain user configuration. In order to completely test the behavior of a system for all possible user configurations, this paper proposes a method that automatically generate GUI test inputs under all possible user configurations. Since testing all possible user configurations is infeasible for nontrivial systems, the method is designed such that the user can sample user configurations. Thus, the proposed method generates GUI test inputs for the behavior of the system dependent on user configurations in addition to the test inputs generated by the existing technique that does not consider user configurations. We implement our method as an automated tool for the Android framework and evaluate it with on five open-source Android apps. The evaluation results show that our method can indeed achieve additional code coverage while preserving code coverage achieved by the existing technique. © Springer International Publishing AG, part of Springer Nature 2019.},
author_keywords={GUI testing;  Software configuration;  Test input generation},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Chen2019517,
author={Chen, T. and Song, T. and He, S. and Liang, A.},
title={A GUI-based automated test system for android applications},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={760},
pages={517-524},
doi={10.1007/978-981-13-0344-9_44},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052912035&doi=10.1007%2f978-981-13-0344-9_44&partnerID=40&md5=50e6534ef7f1a9af5b6b31eb5bd180e5},
affiliation={School of Software, Shanghai Jiao Tong University, Shanghai, China},
abstract={Android application testing has always been a serious problem for mobile developers. To support developers, this paper presents GATS, a GUI-based automated test system for Android apps. This tool uses finite-state machine to learn a model of the app during testing, then uses the learned model to generate user inputs or system event to visit the rest states of the app, and then uses the result of the input to refine the model. The goal of the tool is to trigger crashes. When a crash is happened, GATS will generate a crash report containing screenshot, logcat info with stack trace crash, reproduction steps, and so on. We evaluate GATS on ten Android applications from the top list of several app markets with Monkey, a fuzzing tool from Android platform, and Dynodroid, a previous research. Our result shows that our system has less running time and more bugs found. © Springer Nature Singapore Pte Ltd. 2019.},
author_keywords={Android testing;  Finite-state machine;  GUI testing;  Test automation},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Salihu201917158,
author={Salihu, I.-A. and Ibrahim, R. and Ahmed, B.S. and Zamli, K.Z. and Usman, A.},
title={AMOGA: A Static-Dynamic Model Generation Strategy for Mobile Apps Testing},
journal={IEEE Access},
year={2019},
volume={7},
pages={17158-17173},
doi={10.1109/ACCESS.2019.2895504},
art_number={8630936},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061696384&doi=10.1109%2fACCESS.2019.2895504&partnerID=40&md5=7c0f2992d28d3721a23a84f568a1d379},
affiliation={Department of Software Engineering, Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Parit Raja, 86400, Malaysia; Department of Mathematics and Computer Science, Karlstad University, Karlstad, 651 88, Sweden; Faculty of Computer Systems and Software Engineering, Universiti Malaysia Pahang, Gambang, 26300, Malaysia},
abstract={In the past few years, mobile devices have been increasingly replacing traditional computers, as their capabilities, such as CPU computation, memory, RAM size, and many more, are being enhanced almost to the level of conventional computers. These capabilities are being exploited by mobile apps developers to produce apps that offer more functionalities and optimized performance. To ensure acceptable quality and to meet their specifications (e.g., design), mobile apps need to be tested thoroughly. As the testing process is often tedious, test automation can be the key to alleviating such laborious activities. In the context of the Android-based mobile apps, researchers and practitioners have proposed many approaches to automate the testing process mainly on the creation of the test suite. Although useful, most existing approaches rely on reverse engineering a model of the application under test for test case creation. Often, such approaches exhibit a lack of comprehensiveness, as the application model does not capture the dynamic behavior of the applications extensively due to the incompleteness of reverse engineering approaches. To address this issue, this paper proposes AMOGA, a strategy that uses a hybrid, static-dynamic approach for generating a user interface model from mobile apps for model-based testing. AMOGA implements a novel crawling technique that uses the event list of UI element associated with each event to dynamically exercise the events ordering at the run time to explore the applications' behavior. An experimental evaluation was performed to assess the effectiveness of our strategy by measuring the code coverage and the fault detection capability through the use of mutation testing concept. The results of the experimental assessment showed that AMOGA represents an alternative approach for model-based testing of mobile apps by generating comprehensive models to improve the coverage of the applications. The strategy proved its effectiveness by achieving high code coverage and mutation score for different applications. © 2013 IEEE.},
author_keywords={android apps;  Automated testing;  GUI testing;  mobile apps;  model-based testing;  reverse engineering;  UI Model},
document_type={Article},
source={Scopus},
}

